# 回帰分析とは

# 多重共線性
重回帰分析において説明変数の相関関係が強く、計算結果を狂わせてしまうこと
## 検知方法
Amazon SageMaker Data Wranglerを用いて多重共線性の検知を行える。
以下の方法による検出をサポートしている
### 分散拡大係数（VIF: Variance Inflation Factor）
- 「ある一つの特徴量」をターゲットにして、他の「残りの全特徴量」を使って回帰分析する。 もし、他の変数を使えばその変数を完璧に予測できてしまうなら、「お前、他のやつらのコピーだろ？」と判定される。
- 一般に **VIF > 10** (厳しければ5) だと「多重共線性あり」とみなされ、削除候補になる。
- 「Analysis」タブで「Multicollinearity」を選ぶと、各カラムの VIF スコアが棒グラフで表示される。一番長い棒（スコアが高いやつ）を削除すればOK。

## 主成分分析（PCA）と特微量分解（SVD）
- 相関のある変数同士を合成して、**「主成分」** という新しい軸（無相関な変数）に変換します。 この過程で、**「特異値（Singular Value）」** という値が計算されます。特異値が極端に小さい（0に近い）成分がある場合、それは「元のデータの中に、ペシャンコに潰せる次元（＝無駄な重複）があった」ことを意味します。
- 変数が多すぎてVIFでちまちま消すのが面倒な場合、「PCA」変換を適用して、次元数（変数の数）をギュッと減らすことで多重共線性を一掃します。
- Data Wranglerの「変換（Transform）」メニューにあります。
## LASSO（L1正規化）
- 多重共線性がある（＝似たような変数が2つある）場合、LASSOは「どっちか片方を残して、もう片方を0にする」 という挙動をランダムに行います。
- 「Feature Selection（特徴量選択）」メニューで LASSO を選ぶと、重要な変数は残り、多重共線性の原因となる変数はスコアが0（削除推奨）になります。